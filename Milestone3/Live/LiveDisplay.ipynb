{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video display in live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Video\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/scratch/users/mdelabrassinne/Database/england_epl/2014-2015/2015-02-21_-_18-00_Chelsea_1_-_1_Burnley/1_224p.mkv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.971988\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "video = Video.from_file(path)\n",
    "end = timer()\n",
    "print(timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f92d45b67234926a22df8ada89470c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x1aE\\xdf\\xa3\\x01\\x00\\x00\\x00\\x00\\x00\\x00#B\\x86\\x81\\x01B\\xf7\\x81\\x01B\\xf2\\x81\\x04B\\xf3\\x81\\x08B\\â€¦"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time necessary to load the video is quite high. More than 1 minute. Once it is loaded, it is easy to watch the video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live test of prediction actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sqlite3 as sql\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "from FeaturesData import getPathFeatures, getFeatures, getFeaturesWindow\n",
    "from math import *\n",
    "from Network import Network\n",
    "\n",
    "#from LatenceMeasure import displayMeasureTime, measureTimeWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/users/mdelabrassinne/Database/england_epl/2014-2015/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley/1_baidu_soccer_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "# Select a footblall game in the database\n",
    "db_path = \"/scratch/users/mdelabrassinne/Database/SoccerDB.db\"\n",
    "game = '/scratch/users/mdelabrassinne/Database/england_epl/2014-2015/2015-02-21_-_18-00_Chelsea_1_-_1_Burnley/1_224p.mkv'\n",
    "\n",
    "features = getPathFeatures(game)\n",
    "nms_windows = [20 for i in classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class Results:\n",
    "\n",
    "    def __init__(self, dir_model, features, window_size, classes, nms_window,fps=1):\n",
    "        self.dir_model = dir_model\n",
    "        self.features = features\n",
    "        self.window_size = window_size\n",
    "        self.nb_classes = len(classes)\n",
    "        self.classes = classes\n",
    "        self.nms_window = nms_window\n",
    "        self.fps = fps\n",
    "\n",
    "    def getResults(self, disp_path, conf_path):\n",
    "        \"\"\"\n",
    "        Compute the results of the model from a sequence of features ( of a given size: window_size).\n",
    "        The results are saved in a folder named \"results\" in the directory of the model.\n",
    "\n",
    "        Args:\n",
    "            param dir_model: directory of the model\n",
    "\n",
    "        \"\"\"\n",
    "        dir_results = \"/scratch/users/mdelabrassinne/Results_Test\"\n",
    "\n",
    "        conf_mod_path = os.path.join(self.dir_model, conf_path)\n",
    "        disp_mod_path = os.path.join(self.dir_model, disp_path)\n",
    "        model = Network(conf_mod_path, disp_mod_path)\n",
    "        models = model.get_models()\n",
    "\n",
    "        if not os.path.exists(dir_results):\n",
    "            os.mkdir(dir_results)\n",
    "            \n",
    "        print(f\"Directory {dir_results}\")\n",
    "\n",
    "        def compute_confidences(self, features):\n",
    "            conf = np.zeros((features.shape[0], self.nb_classes))\n",
    "            # Make the predictions\n",
    "            for i in range(0, features.shape[0], self.window_size):\n",
    "                # Make the predictions\n",
    "                if i+self.window_size >= features.shape[0]:\n",
    "                    seq = features[-self.window_size:]\n",
    "                    seq = np.expand_dims(seq, axis=0)\n",
    "                    seq = torch.Tensor(seq)\n",
    "                    seq = seq.transpose(1, 2)\n",
    "                    confidences = (\n",
    "                        (models[0](seq)).detach().numpy()).transpose()\n",
    "                    confidences = np.squeeze(confidences, axis=2)\n",
    "                    confidences = 1 / (1 + np.exp(-confidences))\n",
    "                    displacements = (\n",
    "                        (models[1](seq)).detach().numpy()).transpose()\n",
    "                    displacements = np.squeeze(displacements, axis=2)\n",
    "                    end = features.shape[0] - i\n",
    "                    conf[i:] = self.merge_nms(\n",
    "                        confidences[-end:], displacements[-end:])\n",
    "                else:\n",
    "                    seq = features[i:i+self.window_size]\n",
    "                    seq = np.expand_dims(seq, axis=0)\n",
    "                    seq = torch.Tensor(seq)\n",
    "                    seq = seq.transpose(1, 2)\n",
    "                    confidences = (\n",
    "                        (models[0](seq)).detach().numpy()).transpose()\n",
    "                    confidences = np.squeeze(confidences, axis=2)\n",
    "                    confidences = 1 / (1 + np.exp(-confidences))\n",
    "                    displacements = (\n",
    "                        (models[1](seq)).detach().numpy()).transpose()\n",
    "                    displacements = np.squeeze(displacements, axis=2)\n",
    "                    conf[i:i +\n",
    "                         self.window_size] = self.merge_nms(confidences, displacements)\n",
    "            return conf\n",
    "    \n",
    "        pred_files = []\n",
    "        features = np.load(self.features)       \n",
    "        conf1 = compute_confidences(self, features)\n",
    "\n",
    "        # write the results in a json file\n",
    "        dir_match = os.path.dirname(\"test\")\n",
    "        json_file_name = self.writeResults(conf1, dir_results, dir_match)\n",
    "        pred_files.append(json_file_name)\n",
    "        \n",
    "        return evaluate(pred_files, labels, version=2)\n",
    "\n",
    "    def writeResults(self, conf: np.ndarray,  dir_results: str, dir_match: str):\n",
    "        \"\"\"\n",
    "        Write the results in a JSON file.\n",
    "\n",
    "        Args:\n",
    "            param conf: confidence of the model\n",
    "            param dir_results: directory of the results\n",
    "        \"\"\"\n",
    "\n",
    "        def add_action(self, actions: list, confidences: np.ndarray, half: int) -> list:\n",
    "            for i in range(len(confidences)):\n",
    "                probas = confidences[i]\n",
    "                time = i / self.fps\n",
    "                min = int(time/60)\n",
    "                sec = int((time) % 60)\n",
    "                for c, proba in enumerate(probas):\n",
    "                    if proba > 0.5:\n",
    "                        gt = str(half) + \" - \" + str(min).zfill(2) + \\\n",
    "                            \":\" + str(sec).zfill(2)\n",
    "                        name_action = self.classes[c]\n",
    "                        actions.append({})\n",
    "                        actions[-1][\"label\"] = name_action\n",
    "                        actions[-1][\"position\"] = time * \\\n",
    "                            1000  # time in millseconds\n",
    "                        actions[-1][\"half\"] = half\n",
    "                        actions[-1][\"confidence\"] = proba\n",
    "                        actions[-1][\"gameTime\"] = gt\n",
    "\n",
    "            return actions\n",
    "\n",
    "        my_path = dir_results\n",
    "        match_name = \"\"\n",
    "        league_names = [\"england_epl\", \"europe_uefa-champions-league\",\n",
    "                        \"france_ligue-1\", \"germany_bundesliga\", \"italy_serie-a\"]\n",
    "        for league in league_names:\n",
    "            if league in dir_match:\n",
    "                match_name = league\n",
    "                break\n",
    "\n",
    "        season_year = [\"2014-2015\", \"2015-2016\", \"2016-2017\",\n",
    "                       \"2017-2018\", \"2018-2019\", \"2019-2020\"]\n",
    "        for season in season_year:\n",
    "            if season in dir_match:\n",
    "                my_path = os.path.join(my_path, season)\n",
    "                match_name = os.path.join(match_name, season)\n",
    "                break\n",
    "        match_string = copy.deepcopy(dir_match[(len(my_path)+1):-11])\n",
    "        match_string = match_string.replace(\"_\", \" \")\n",
    "\n",
    "        my_path = os.path.join(my_path, match_string)\n",
    "        match_name = os.path.join(match_name, match_string)\n",
    "\n",
    "        json_dict = {}\n",
    "\n",
    "        # Define the half based on the name of the video that is being processed\n",
    "        half = 1 if \"1_224p.mkv\" or \"1_720p.mkv\" in dir_match else 2\n",
    "\n",
    "        json_dict[\"UrlLocal\"] = match_name\n",
    "        json_dict[\"predictions\"] = add_action(self, [], conf, half)\n",
    "\n",
    "        json_object = json.dumps(json_dict, indent=4)\n",
    "\n",
    "        json_file_name = os.path.join(dir_match, f\"{match_name}.json\")\n",
    "        # match name equals to path of last folder\n",
    "        match_name = match_name.split(\"/\")[-1]\n",
    "\n",
    "        # Writing\n",
    "        json_file_name = os.path.join(dir_results, f\"{match_name}.json\")\n",
    "\n",
    "        # Writing\n",
    "        with open(json_file_name, \"w\") as outfile:\n",
    "            outfile.write(json_object)\n",
    "\n",
    "        return json_file_name\n",
    "    \n",
    "    def compute_update_confidence(self, confidences: np.ndarray, displacements: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Computes the updated confidences using the displacements.\n",
    "\n",
    "        Args:\n",
    "            confidences (np.ndarray): Confidence of each class for each time step of each video.\n",
    "            displacements (np.ndarray): Displacement of each class for each time step of each video.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Updated confidences of each class for each time step of each video.\n",
    "        \"\"\"\n",
    "        T = confidences.shape[0]\n",
    "        K = confidences.shape[1]\n",
    "\n",
    "        displacements = np.round(displacements * self.fps).astype(int)\n",
    "        output = np.zeros_like(confidences)\n",
    "        classes = np.arange(K)\n",
    "\n",
    "        for t in range(T):\n",
    "            disp = displacements[t, :]\n",
    "            idx = t - disp\n",
    "            idx = np.clip(idx, 0, T - 1)\n",
    "            output[idx, classes] = np.maximum(output[idx, classes], confidences[t, classes])\n",
    "        \n",
    "        return output    \n",
    "    \n",
    "    def merge_nms(self, confidences: np.ndarray, displacements: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Evaluates the updated confidences using the displacements and Normalized Maximum Suppression (NMS) on time series.\n",
    "\n",
    "        Args:\n",
    "            confidences (np.ndarray): Confidence of each class for each time step of each video.\n",
    "            displacements (np.ndarray): Displacement of each class for each time step of each video. The displacements \n",
    "                are in seconds.\n",
    "        Returns:\n",
    "            np.ndarray: Updated confidences of each class for each time step of each video.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check the shape of the confidences and displacements\n",
    "        assert confidences.shape == displacements.shape, \"The shape of the confidences and displacements should be the same.\"\n",
    "\n",
    "        # 1. Compute the updated confidences using the displacements\n",
    "        # 2. Compute the NMS on the time series\n",
    "\n",
    "        # 1. Compute the updated confidences using the displacements\n",
    "        updated_confidences = self.compute_update_confidence(confidences, displacements)\n",
    "\n",
    "        # 2. Compute the NMS on the time series\n",
    "        nms_confidences = self.compute_nms(updated_confidences)\n",
    "        return nms_confidences\n",
    "       \n",
    "\n",
    "    def compute_nms(self, confidences: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Computes the NMS on the time series for each class seperately.\n",
    "\n",
    "        Args:\n",
    "            confidences (np.ndarray): Updated confidences of each class for each time step of each video.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: NMS confidences of each class for each time step of each video.\n",
    "        \"\"\"\n",
    "        T = confidences.shape[0]\n",
    "        K = confidences.shape[1]\n",
    "\n",
    "        output = confidences.copy()\n",
    "\n",
    "        for k in range(K):\n",
    "            nms_window = self.nms_window[k]\n",
    "            nms_window = int(nms_window * self.fps)\n",
    "            preds = confidences[:, k]\n",
    "            copy_preds = preds.copy()\n",
    "\n",
    "            # Apply NMS for a window of size nms_window seconds\n",
    "            max_idx = np.argmax(copy_preds)\n",
    "            max_val = copy_preds[max_idx]\n",
    "\n",
    "            while max_val > 0:\n",
    "                start = max(0, max_idx - nms_window)\n",
    "                end = min(T, max_idx + nms_window + 1)\n",
    "\n",
    "                preds[start:end] = 0\n",
    "                preds[max_idx] = max_val\n",
    "\n",
    "                copy_preds[start:end] = 0\n",
    "                max_idx = np.argmax(copy_preds)\n",
    "                max_val = copy_preds[max_idx]\n",
    "            \n",
    "            output[:, k] = preds\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /scratch/users/mdelabrassinne/Results_Test\n"
     ]
    }
   ],
   "source": [
    "dir_model = \"/home/mdelabrassinne/DSproject/Milestone3/Time Measures\"\n",
    "window_size = 64\n",
    "classes = ['Kick-off', \n",
    "           'Ball out of play', \n",
    "           'Throw-in', 'Foul', \n",
    "           'Clearance', \n",
    "           'Indirect free-kick', \n",
    "           'Shots on target', \n",
    "           'Corner', \n",
    "           'Shots off target', \n",
    "           'Direct free-kick', \n",
    "           'Yellow card', \n",
    "           'Substitution', \n",
    "           'Red card', \n",
    "           'Offside', \n",
    "           'Goal', \n",
    "           'Penalty', \n",
    "           'Yellow->red card']\n",
    "res = Results(dir_model, features, window_size, classes, nms_windows)\n",
    "\n",
    "conf = \"confidence_window_64.pt\"\n",
    "disp = \"disp_window_64.pt\"\n",
    " \n",
    "res.getResults(disp,conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DSproject]",
   "language": "python",
   "name": "conda-env-DSproject-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
